<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Face Detector - duyhandsome</title>
	<link rel="stylesheet" href="style.css">
	<style>
		#container {
			width: 100%;
			position: relative;
		}

		#container img {
			width: 100%;
			height: 100%;
		}

		canvas {
			position: absolute;
			top: 0;
			left: 0;
		}
	</style>
	<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/toastify-js/src/toastify.min.css">

</head>

<body>
	<h2>Face Detector with duyhandsome. </h2>
	<p>Face Detector knew: </p>
	<ul>
		<li>Fukada Eimi</li>
		<li>Rina Ishihara</li>
		<li>Takizawa Laura</li>
		<li>Yua Mikami</li>
	</ul>

	<p id="loading"> &hearts; Loading.... Please wait a little bit &hearts; </p>
	<input type="file" name="file" id="file-input" />

	<div id="container"></div>
</body>

<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/toastify-js"></script>
<script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.js"
	integrity="sha256-JOJ7NmVm2chxYZ1KPcAYd2bwVK7NaFj9QKMp7DClews=" crossorigin="anonymous"></script>
<script src="scripts.js"></script>
<script> 
const container = document.querySelector('#container');
const fileInput = document.querySelector('#file-input');

// TrainingData
async function loadTrainingData() {
	const labels = ['Fukada Eimi', 'Rina Ishihara', 'Takizawa Laura', 'Yua Mikami']

	const faceDescriptors = []
	for (const label of labels) {
		const descriptors = []
		for (let i = 1; i <= 4; i++) {
			const image = await faceapi.fetchImage(`/data/${label}/${i}.jpeg`)
			const detection = await faceapi.detectSingleFace(image).withFaceLandmarks().withFaceDescriptor()
			descriptors.push(detection.descriptor)
		}
		faceDescriptors.push(new faceapi.LabeledFaceDescriptors(label, descriptors))
		Toastify({
			text: `Trained - ${label}!`
		}).showToast();
	}

	return faceDescriptors
}

let faceMatcher
async function init() {
	await Promise.all([
		faceapi.loadSsdMobilenetv1Model('/models'),
		faceapi.loadFaceRecognitionModel('/models'),
		faceapi.loadFaceLandmarkModel('/models'),
	])


	Toastify({
		text: "Model Detection has been loaded!",
	}).showToast();

	const trainingData = await loadTrainingData()
	faceMatcher = new faceapi.FaceMatcher(trainingData, 0.6)

	console.log(faceMatcher)
	document.querySelector("#loading").remove();
}

init()

fileInput.addEventListener('change', async () => {
	const files = fileInput.files;

	const image = await faceapi.bufferToImage(files[0]);
	const canvas = faceapi.createCanvasFromMedia(image);

	container.innerHTML = ''
	container.append(image);
	container.append(canvas);

	const size = {
		width: image.width,
		height: image.height
	}

	faceapi.matchDimensions(canvas, size)

	const detections = await faceapi.detectAllFaces(image).withFaceLandmarks().withFaceDescriptors()
	const resizedDetections = faceapi.resizeResults(detections, size)

	// faceapi.draw.drawDetections(canvas, resizedDetections)


	for (const detection of resizedDetections) {
		const drawBox = new faceapi.draw.DrawBox(detection.detection.box, {
			label: faceMatcher.findBestMatch(detection.descriptor).toString()
		})
		drawBox.draw(canvas)
	}
})
</script>

</html>
